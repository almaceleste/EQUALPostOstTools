{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0de554kw/EQUALPostOstTools/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wishper FE"
      ],
      "metadata": {
        "id": "83WE79Xftn_h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abPD5wSEtkqu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run this to setup the application\n",
        "\n",
        "#@markdown * Install OpenAI Whisper\n",
        "#@markdown * Download pretrained model\n",
        "#@markdown * Used sources:\n",
        "\n",
        "#@markdown https://github.com/magenta/ddsp/blob/main/ddsp/colab/colab_utils.py\n",
        "\n",
        "#@markdown https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install pydub librosa\n",
        "\n",
        "\n",
        "import whisper\n",
        "from IPython import display as adsp\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import base64\n",
        "import io\n",
        "import tempfile\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "\n",
        "DEFAULT_SAMPLE_RATE = 16000\n",
        "\n",
        "def record_audio(seconds=3,\n",
        "                 sample_rate=DEFAULT_SAMPLE_RATE,\n",
        "                 normalize_db=0.1):\n",
        "    \"\"\"Record audio from the browser in colab using javascript.\n",
        "    Based on: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be\n",
        "    Args:\n",
        "      seconds: Number of seconds to record.\n",
        "      sample_rate: Resample recorded audio to this sample rate.\n",
        "      normalize_db: Normalize the audio to this many decibels. Set to None to skip\n",
        "        normalization step.\n",
        "    Returns:\n",
        "      An array of the recorded audio at sample_rate.\n",
        "    \"\"\"\n",
        "    # Use Javascript to record audio.\n",
        "    record_js_code = \"\"\"\n",
        "      const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "      const b2text = blob => new Promise(resolve => {\n",
        "        const reader = new FileReader()\n",
        "        reader.onloadend = e => resolve(e.srcElement.result)\n",
        "        reader.readAsDataURL(blob)\n",
        "      })\n",
        "      var record = time => new Promise(async resolve => {\n",
        "        stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "        recorder = new MediaRecorder(stream)\n",
        "        chunks = []\n",
        "        recorder.ondataavailable = e => chunks.push(e.data)\n",
        "        recorder.start()\n",
        "        await sleep(time)\n",
        "        recorder.onstop = async ()=>{\n",
        "          blob = new Blob(chunks)\n",
        "          text = await b2text(blob)\n",
        "          resolve(text)\n",
        "        }\n",
        "        recorder.stop()\n",
        "      })\n",
        "      \"\"\"\n",
        "    print('Starting recording for {} seconds...'.format(seconds))\n",
        "    adsp.display(adsp.Javascript(record_js_code))\n",
        "    audio_string = output.eval_js('record(%d)' % (seconds * 1000.0))\n",
        "    print('Finished recording!')\n",
        "    audio_bytes = base64.b64decode(audio_string.split(',')[1])\n",
        "    return audio_bytes_to_np(audio_bytes,\n",
        "                             sample_rate=sample_rate,\n",
        "                             normalize_db=normalize_db)\n",
        "\n",
        "\n",
        "def audio_bytes_to_np(wav_data,\n",
        "                      sample_rate=DEFAULT_SAMPLE_RATE,\n",
        "                      normalize_db=0.1):\n",
        "    \"\"\"Convert audio file data (in bytes) into a numpy array.\n",
        "    Saves to a tempfile and loads with librosa.\n",
        "    Args:\n",
        "      wav_data: A byte stream of audio data.\n",
        "      sample_rate: Resample recorded audio to this sample rate.\n",
        "      normalize_db: Normalize the audio to this many decibels. Set to None to skip\n",
        "        normalization step.\n",
        "    Returns:\n",
        "      An array of the recorded audio at sample_rate.\n",
        "    \"\"\"\n",
        "    # Parse and normalize the audio.\n",
        "    audio = AudioSegment.from_file(io.BytesIO(wav_data))\n",
        "    audio.remove_dc_offset()\n",
        "    if normalize_db is not None:\n",
        "        audio.normalize(headroom=normalize_db)\n",
        "    # Save to tempfile and load with librosa.\n",
        "    with tempfile.NamedTemporaryFile(suffix='.wav') as temp_wav_file:\n",
        "        fname = temp_wav_file.name\n",
        "        audio.export(fname, format='wav')\n",
        "        audio_np, unused_sr = librosa.load(fname, sr=sample_rate)\n",
        "    return audio_np\n",
        "\n",
        "\n",
        "def upload_audio(sample_rate=DEFAULT_SAMPLE_RATE, normalize_db=None):\n",
        "    \"\"\"Load a collection of audio files (.wav, .mp3) from disk into colab.\n",
        "    Args:\n",
        "      sample_rate: Resample recorded audio to this sample rate.\n",
        "      normalize_db: Normalize the audio to this many decibels. Set to None to skip\n",
        "        normalization step.\n",
        "    Returns:\n",
        "      An tuple of lists, (filenames, numpy_arrays).\n",
        "    \"\"\"\n",
        "    audio_files = files.upload()\n",
        "    fnames = list(audio_files.keys())\n",
        "    if len(fnames) == 0:\n",
        "        return None\n",
        "\n",
        "    return audio_bytes_to_np(audio_files[fnames[0]],\n",
        "                             sample_rate=sample_rate,\n",
        "                             normalize_db=normalize_db)\n",
        "\n",
        "model = whisper.load_model(\"small\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to Record or Upload Audio\n",
        "#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav)\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "SAMPLE_RATE = 22050\n",
        "\n",
        "def transcribe(audio):\n",
        "  ret = model.transcribe(audio)\n",
        "  text = ret['text']\n",
        "  print(\"\\n\\n\")\n",
        "  pprint(text)\n",
        "\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  transcribe(audio)\n",
        "\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  transcribe(audio)\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Your Voice\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  button = widgets.Button(description=\"Upload Voice File\")\n",
        "  button.on_click(_upload_audio)\n",
        "  _upload_audio(\"\")"
      ],
      "metadata": {
        "id": "ooOic7hqxi1R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}